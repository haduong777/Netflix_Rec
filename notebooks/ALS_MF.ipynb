{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from typing import List, Dict\n",
        "from scipy.sparse import csr_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from als import ALS"
      ],
      "metadata": {
        "id": "rURDXNXX7Zsl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8IYzXFL7rEe",
        "outputId": "54bb8b7c-13e6-4acc-ffb4-c476c3187f35"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/gdrive/MyDrive/Netflix_Prize/split/train'\n",
        "output_dir = '/gdrive/MyDrive/Netflix_Prize/results'\n",
        "val_dir = '/gdrive/MyDrive/Netflix_Prize/split/validation'\n",
        "checkpoint_dir = '/gdrive/MyDrive/Netflix_Prize/checkpoints'"
      ],
      "metadata": {
        "id": "7jrnU7vB7rEf"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(data_dir: str):\n",
        "  partition_files = []\n",
        "\n",
        "  pattern = re.compile(r'part_(\\d+)_(\\d+)\\.parquet$')\n",
        "\n",
        "  for filename in os.listdir(data_dir):\n",
        "    match = pattern.match(filename)\n",
        "    if match:\n",
        "        file_path = os.path.join(data_dir, filename)\n",
        "        part_num = int(match.group(1))\n",
        "        group_num = int(match.group(2))\n",
        "\n",
        "        partition_files.append({\n",
        "            'path': file_path,\n",
        "            'part': part_num,\n",
        "            'group': group_num\n",
        "        })\n",
        "\n",
        "  # sorted partitions in order\n",
        "  partition_files.sort(key=lambda x: (x['part'], x['group']))\n",
        "  return partition_files"
      ],
      "metadata": {
        "id": "FYnzH3fW-IV5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_partition_files = get_data(data_dir)\n",
        "print(f\"Number of training partitions: {len(train_partition_files)}\")\n",
        "val_partition_files = get_data(val_dir)\n",
        "print(f\"Number of validation partitions: {len(val_partition_files)}\")\n",
        "\n",
        "# testing\n",
        "sample_train_partitions = train_partition_files[:5]\n",
        "sample_val_partitions = val_partition_files[:5]\n",
        "print(f\"Train: {sample_train_partitions[0]}\")\n",
        "print(f\"Val: {sample_train_partitions[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mtb8sOy7x7v",
        "outputId": "62e03fcf-f63b-45f4-bee1-9721375fc871"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training partitions: 34\n",
            "Number of validation partitions: 34\n",
            "Train: {'path': '/gdrive/MyDrive/Netflix_Prize/split/train/part_1_0.parquet', 'part': 1, 'group': 0}\n",
            "Val: {'path': '/gdrive/MyDrive/Netflix_Prize/split/train/part_1_0.parquet', 'part': 1, 'group': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_id(partition_files: List[Dict], sample_size=None):\n",
        "  \"\"\"\n",
        "  Map user and movie ids to denser indicies -> for matrix factorization\n",
        "  \"\"\"\n",
        "\n",
        "  user_ids = set()\n",
        "  movie_ids = set()\n",
        "\n",
        "  if sample_size and sample_size < len(partition_files):\n",
        "    partition_sample = random.sample(partition_files, sample_size)\n",
        "  else:\n",
        "    partition_sample = partition_files\n",
        "\n",
        "  for partition in tqdm(partition_sample, desc=\"Mapping IDs\"):\n",
        "    df = pd.read_parquet(partition['path'], columns=['user_id', 'movie_id'])\n",
        "\n",
        "    user_ids.update(df['user_id'].unique())\n",
        "    movie_ids.update(df['movie_id'].unique())\n",
        "\n",
        "  user_id_map = {user_id: idx for idx, user_id in enumerate(sorted(user_ids))}\n",
        "  movie_id_map = {movie_id: idx for idx, movie_id in enumerate(sorted(movie_ids))}\n",
        "\n",
        "  print(f\"Map successful for {len(user_id_map)} users, {len(movie_id_map)} movies\")\n",
        "\n",
        "  return user_id_map, movie_id_map\n",
        "\n",
        "user_map, movie_map = map_id(train_partition_files, sample_size=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIQ78ZPE9Lig",
        "outputId": "a2456bf7-0128-45ad-dce3-b135ebce97dc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Mapping IDs: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map successful for 428145 users, 2649 movies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 each as a test\n",
        "train_partitions = sample_train_partitions\n",
        "val_partitions = sample_val_partitions"
      ],
      "metadata": {
        "id": "S332c5EtBu2E"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init model - small test values\n",
        "\n",
        "model = ALS(\n",
        "    num_factors=10,\n",
        "    lambda_reg=0.1,\n",
        "    num_iters=5,\n",
        "    val_interval=2\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    partitions=train_partitions,\n",
        "    user_map=user_map,\n",
        "    movie_map=movie_map,\n",
        "    checkpoint_dir=checkpoint_dir\n",
        ")\n",
        "\n",
        "model.save_model(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXdMIjcAC8nx",
        "outputId": "cf2066a8-2a34-40fa-b3c5-e0c4f0bfefb6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building sparse matrices for 428145 users, and 2649 movies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building sparse matrix...:  20%|██        | 1/5 [00:05<00:21,  5.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Skipping partition /gdrive/MyDrive/Netflix_Prize/split/train/part_1_0.parquet due to no valid mappings found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rBuilding sparse matrix...:  40%|████      | 2/5 [00:08<00:12,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Skipping partition /gdrive/MyDrive/Netflix_Prize/split/train/part_1_1.parquet due to no valid mappings found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building sparse matrix...: 100%|██████████| 5/5 [00:28<00:00,  5.70s/it]\n",
            "ALS Optimization:  20%|██        | 1/5 [01:15<05:00, 75.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint to /gdrive/MyDrive/Netflix_Prize/checkpoints/checkpoint_1.npz\n",
            "Saved checkpoint to /gdrive/MyDrive/Netflix_Prize/checkpoints/checkpoint_2.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rALS Optimization:  40%|████      | 2/5 [02:34<03:52, 77.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2 -- RMSE: 0.6124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rALS Optimization:  60%|██████    | 3/5 [03:51<02:34, 77.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint to /gdrive/MyDrive/Netflix_Prize/checkpoints/checkpoint_3.npz\n",
            "Saved checkpoint to /gdrive/MyDrive/Netflix_Prize/checkpoints/checkpoint_4.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rALS Optimization:  80%|████████  | 4/5 [05:09<01:17, 77.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 4 -- RMSE: 0.5148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ALS Optimization: 100%|██████████| 5/5 [06:25<00:00, 77.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint to /gdrive/MyDrive/Netflix_Prize/checkpoints/checkpoint_5.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Model saved at /gdrive/MyDrive/Netflix_Prize/results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEED EVAL AND FIX INCREASING COMPUTATION TIME ISSUE, IMPLEMENT ON-LINE LEARNING TO ADDRESS MEMORY PROBLEM."
      ],
      "metadata": {
        "id": "8RSYUdmcDwJ4"
      },
      "execution_count": 63,
      "outputs": []
    }
  ]
}