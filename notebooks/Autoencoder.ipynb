{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "h6IdZY_JkdlI",
    "outputId": "6397b3c2-d00b-4b61-8ee7-4f126fd7fb3a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from typing import List, Dict, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.exceptions import TrialPruned\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_partitions': 5,\n",
    "    'tuning_epoch': 5,\n",
    "    'checkpoint_interval': 5,\n",
    "    'num_tuning_trials': 3,\n",
    "    'seed': 42 # or None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..') \n",
    "\n",
    "from src.models.autoencoder import AutoEncoder\n",
    "from src.models.autoencoder_trainer import *\n",
    "from src.data.data_utils import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "q5SV28rPnfzI"
   },
   "outputs": [],
   "source": [
    "data_dir = '../NETFLIX_DATA/partitions/train'\n",
    "val_dir = '../NETFLIX_DATA/partitions/validation'\n",
    "checkpoint_dir = '../model_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aN0OQaig8krT",
    "outputId": "fb7c2ba2-b2c0-4df0-87e4-a5368a86de8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training partitions: 34\n",
      "Number of validation partitions: 34\n",
      "Train EX: {'path': '../NETFLIX_DATA/partitions/train/part_1_7.parquet', 'part': 1, 'group': 7}\n",
      "Val EX: {'path': '../NETFLIX_DATA/partitions/validation/part_1_7.parquet', 'part': 1, 'group': 7}\n"
     ]
    }
   ],
   "source": [
    "# retreive training data info\n",
    "train_partition_files = get_data(data_dir)\n",
    "print(f\"Number of training partitions: {len(train_partition_files)}\")\n",
    "val_partition_files = get_data(val_dir)\n",
    "print(f\"Number of validation partitions: {len(val_partition_files)}\")\n",
    "\n",
    "if CONFIG['seed'] is not None:\n",
    "    random.seed(CONFIG['seed'])\n",
    "\n",
    "# testing\n",
    "sample_train_partitions = random.sample(train_partition_files, CONFIG['num_partitions'])\n",
    "\n",
    "sample_val_partitions = []\n",
    "for partition in sample_train_partitions:\n",
    "  val_partition = partition.copy()\n",
    "  val_partition['path'] = partition['path'].replace('train', 'validation')\n",
    "  sample_val_partitions.append(val_partition)\n",
    "\n",
    "\n",
    "print(f\"Train EX: {sample_train_partitions[0]}\")\n",
    "print(f\"Val EX: {sample_val_partitions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_bZtDnAn-kV",
    "outputId": "b122695f-18df-4a89-9a85-6761ebd0ce64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping IDs: 100%|██████████| 5/5 [00:01<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map successful for 423631 users, 2880 movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build user_map and movie_map\n",
    "user_map, movie_map = map_id(sample_train_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading users' rating profile 1/5: 100%|██████████| 1828517/1828517 [01:43<00:00, 17633.02it/s]\n",
      "Loading users' rating profile 2/5: 100%|██████████| 2772664/2772664 [02:31<00:00, 18299.16it/s]\n",
      "Loading users' rating profile 3/5:  48%|████▊     | 1337590/2776385 [01:15<01:21, 17663.65it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preload user rating profiles\n",
    "\n",
    "train_user_data = AutoEncoder.load_user_data(partitions=sample_train_partitions, \n",
    "                                             user_map=user_map)\n",
    "\n",
    "validation_user_data = AutoEncoder.load_validation_data(partitions=sample_val_partitions, \n",
    "                                                        user_map=user_map,\n",
    "                                                        movie_map=movie_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna objective\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"num_epochs\": CONFIG['tuning_epoch'],\n",
    "        \"batch_size\": 512,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.0001, 0.001, log=True),\n",
    "        \"hidden_dims\": trial.suggest_categorical(\"hidden_dims\", \n",
    "                                                 [[1024,256,128], [512,256,128], [256,128], [512,128]]),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.3, 0.7),\n",
    "        \"l2_reg\": trial.suggest_float(\"l2_reg\", 0.00001, 0.01, log=True),\n",
    "        \"checkpoint_interval\": CONFIG['checkpoint_interval'],\n",
    "        \"eval_interval\": 1,\n",
    "    }\n",
    "\n",
    "                #[[512,256,128], [256,128], [512,128]]\n",
    "\n",
    "    try:\n",
    "        print(params)\n",
    "        \n",
    "        model, rmse = train_autoencoder(\n",
    "            train_partitions=sample_train_partitions,\n",
    "            user_map=user_map,\n",
    "            movie_map=movie_map,\n",
    "            validation_partitions=sample_val_partitions,\n",
    "            checkpoint_dir=checkpoint_dir,\n",
    "            trial=trial,\n",
    "            user_data=train_user_data,\n",
    "            validation_data=validation_user_data,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        return float(rmse)\n",
    "    except optuna.TrialPruned:\n",
    "        raise # reraise prune error for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "eQ5xmua2oCPe",
    "outputId": "97341bfa-9213-4327-c797-d8fdd32f9c89"
   },
   "outputs": [],
   "source": [
    "# tuning\n",
    "warnings.filterwarnings(\"ignore\", module=\"optuna.*\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=f\"autoencoder_tuning_{CONFIG['num_partitions']}_samples\", \n",
    "    direction='minimize',\n",
    "    \n",
    "    # prune after 2 trials, after 1 if really bad\n",
    "    pruner=MedianPruner(n_startup_trials=2, n_warmup_steps=1),\n",
    "    \n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    storage=f\"sqlite:///optuna_study_{CONFIG['num_partitions']}_samples.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=CONFIG['num_tuning_trials'], timeout=6*3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best trial\")\n",
    "print(f\"RMSE: {study.best_value:.4f}\")\n",
    "print(f\"Params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total trials run: {len(study.trials)}\")\n",
    "completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "print(f\"Completed trials: {len(completed_trials)}\")\n",
    "\n",
    "if len(completed_trials) > 0:\n",
    "    print(f\"Best RMSE so far: {study.best_value:.4f}\")\n",
    "    print(f\"Best params: {study.best_params}\")\n",
    "    \n",
    "    # Check if there's convergence\n",
    "    recent_trials = completed_trials[-5:]  # Last 5 completed\n",
    "    recent_values = [t.value for t in recent_trials]\n",
    "    print(f\"Recent RMSE values: {recent_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = set(train_user_data.keys())\n",
    "val_users = set(validation_user_data.keys())\n",
    "overlap = train_users.intersection(val_users)\n",
    "print(f\"User overlap: {len(overlap)} / {len(val_users)} = {len(overlap)/len(val_users)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check user/movie overlap\n",
    "print(\"User overlap analysis:\")\n",
    "print(f\"Train users: {len(train_user_data)}\")\n",
    "print(f\"Val users: {len(validation_user_data)}\")\n",
    "user_overlap = len(set(train_user_data.keys()) & set(validation_user_data.keys()))\n",
    "print(f\"Overlapping users: {user_overlap}\")\n",
    "\n",
    "# 2. Check if validation is too easy\n",
    "val_ratings = []\n",
    "for user_ratings in validation_user_data.values():\n",
    "    val_ratings.extend([r for _, r in user_ratings])\n",
    "print(f\"Validation rating distribution: {np.histogram(val_ratings, bins=5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
